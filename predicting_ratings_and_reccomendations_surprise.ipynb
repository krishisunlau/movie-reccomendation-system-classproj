{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvDCQrwbSckV",
        "outputId": "8d364dce-afc5-43eb-a0c3-cc15ad5caade"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (from surprise) (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, SVDpp, Reader\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from surprise import SVDpp, Reader, Dataset, accuracy\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import ndcg_score\n"
      ],
      "metadata": {
        "id": "nojKMH8nS0Mm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = 'training_data.csv'\n",
        "test_data_path = 'testing_data.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_data_path)\n",
        "test_df = pd.read_csv(test_data_path)"
      ],
      "metadata": {
        "id": "0bvIbXz6S13Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up surprise and calculations\n",
        "def converter_surprise(training_dataframe, testing_dataframe):\n",
        "    reader = Reader(rating_scale=(0, 5))  # ratings' range\n",
        "    trainset = Dataset.load_from_df(training_dataframe[['userId', 'movieId', 'rating']], reader)\n",
        "    testset = Dataset.load_from_df(testing_dataframe[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = trainset.construct_trainset(trainset.raw_ratings)\n",
        "    testset = testset.construct_testset(testset.raw_ratings)\n",
        "    return trainset, testset\n",
        "\n",
        "trainset, testset = converter_surprise(train_df, test_df)\n",
        "\n",
        "def calculate_rmse_mae(model, trainset, testset):\n",
        "    model.fit(trainset)\n",
        "\n",
        "    test_predictions = model.test(testset)\n",
        "\n",
        "    rmse = accuracy.rmse(test_predictions)\n",
        "    mae = accuracy.mae(test_predictions)\n",
        "\n",
        "    return rmse, mae\n"
      ],
      "metadata": {
        "id": "R7u8M6wNTAVI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regular svd\n",
        "svd_model = SVD()\n",
        "svd_rmse, svd_mae = calculate_rmse_mae(svd_model, trainset, testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GoUg0k2UF0F",
        "outputId": "f297f3ce-bb11-4016-99b5-bdf7e01bc6ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8695\n",
            "MAE:  0.6682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# svdpp\n",
        "svdpp_model = SVDpp()\n",
        "svdpp_rmse, svdpp_mae = calculate_rmse_mae(svdpp_model, trainset, testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pf1O8QiUVPw",
        "outputId": "92a1e06a-69d5-49b5-82ba-3756becc7ef3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8584\n",
            "MAE:  0.6594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#svdpp has better values so using that model"
      ],
      "metadata": {
        "id": "ue82jfmrlV3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top n\n",
        "def get_top_n_recommendations(predictions, n):\n",
        "    recommendations = defaultdict(list)\n",
        "    actual_ratings = defaultdict(list)\n",
        "\n",
        "    for user_id, item_id, actual_rating, estimated_rating, _ in predictions:\n",
        "        recommendations[user_id].append((item_id, estimated_rating))\n",
        "        actual_ratings[user_id].append((item_id, actual_rating))\n",
        "\n",
        "    for user_id, recs in recommendations.items():\n",
        "        recs.sort(key=lambda x: x[1], reverse=True)\n",
        "        recommendations[user_id] = recs[:n]\n",
        "\n",
        "    return recommendations, actual_ratings\n"
      ],
      "metadata": {
        "id": "uIIkyg5-XlrG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#precision an recall\n",
        "def calculate_precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    user_estimated_true = defaultdict(list)\n",
        "\n",
        "    for user_id, _, true_rating, estimated_rating, _ in predictions:\n",
        "        user_estimated_true[user_id].append((estimated_rating, true_rating))\n",
        "\n",
        "    precision_values = dict()\n",
        "    recall_values = dict()\n",
        "\n",
        "    for user_id, ratings in user_estimated_true.items():\n",
        "        ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        relevant_items_count = sum((true_rating >= threshold) for _, true_rating in ratings)\n",
        "        recommended_items_at_k = sum((estimated_rating >= threshold) for estimated_rating, _ in ratings[:k])\n",
        "        relevant_and_recommended_at_k = sum(((true_rating >= threshold) and (estimated_rating >= threshold))\n",
        "                                            for estimated_rating, true_rating in ratings[:k])\n",
        "\n",
        "        precision_values[user_id] = relevant_and_recommended_at_k / recommended_items_at_k if recommended_items_at_k != 0 else 1\n",
        "        recall_values[user_id] = relevant_and_recommended_at_k / relevant_items_count if relevant_items_count != 0 else 1\n",
        "\n",
        "    avg_precision = sum(precision for precision in precision_values.values()) / len(precision_values)\n",
        "    avg_recall = sum(recall for recall in recall_values.values()) / len(recall_values)\n",
        "\n",
        "    return avg_precision, avg_recall"
      ],
      "metadata": {
        "id": "BWI0n0KUXtqo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dcg_at_k(scores):\n",
        "    return scores[0] + sum(score / math.log(index, 2) for score, index in zip(scores[1:], range(2, len(scores) + 1)))\n",
        "\n",
        "def calculate_ndcg_at_k(scores):\n",
        "    ideal_dcg = calculate_dcg_at_k(sorted(scores, reverse=True))\n",
        "    return calculate_dcg_at_k(scores) / ideal_dcg if ideal_dcg > 0.0 else 0.0\n"
      ],
      "metadata": {
        "id": "H2T9heGCX3Lp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_performance(model, trainset, testset, n=10):\n",
        "\n",
        "    model.fit(trainset)\n",
        "\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    top_recs, true_ratings = get_top_n_recommendations(predictions, n)\n",
        "\n",
        "    avg_precision, avg_recall = calculate_precision_recall_at_k(predictions, k=n)\n",
        "    f_measure_avg = (2 * avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) != 0 else 0\n",
        "\n",
        "    ndcg_scores = dict()\n",
        "    for user_id, recs in top_recs.items():\n",
        "        scores = []\n",
        "        for item_id, estimated_rating in recs:\n",
        "            found = False\n",
        "            original_user_ratings = true_ratings[user_id]\n",
        "            for i, rating in original_user_ratings:\n",
        "                if item_id == i:\n",
        "                    scores.append(rating)\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                scores.append(0)\n",
        "        ndcg_scores[user_id] = calculate_ndcg_at_k(scores)\n",
        "\n",
        "    avg_ndcg = sum(ndcg for ndcg in ndcg_scores.values()) / len(ndcg_scores)\n",
        "\n",
        "    # storing reccomendations for future use in optional section\n",
        "    recommendations_data = []\n",
        "\n",
        "    for user_id, recs in top_recs.items():\n",
        "        recs_row = {'userId': user_id}\n",
        "        for i, (item_id, estimated_rating) in enumerate(recs):\n",
        "            recs_row[f'rec{i+1}_movieId'] = item_id\n",
        "            recs_row[f'rec{i+1}_rating'] = estimated_rating\n",
        "        recommendations_data.append(recs_row)\n",
        "\n",
        "    recommendations_df = pd.DataFrame(recommendations_data)\n",
        "\n",
        "    return avg_precision, avg_recall, f_measure_avg, avg_ndcg, predictions, recommendations_df\n",
        "\n",
        "model = SVDpp()\n",
        "avg_precision, avg_recall, avg_f_measure, avg_ndcg, test_predictions, recommendations_df = evaluate_model_performance(\n",
        "    model, trainset, testset, n=10\n",
        ")\n",
        "\n",
        "print(f\"Average Precision: {avg_precision}\")\n",
        "print(f\"Average Recall: {avg_recall}\")\n",
        "print(f\"Average F-measure: {avg_f_measure}\")\n",
        "print(f\"Average NDCG: {avg_ndcg}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMDzReNVjMmm",
        "outputId": "56a57175-5bdf-497d-98c3-fa248d357b25"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.790362347124642\n",
            "Average Recall: 0.5442763504878859\n",
            "Average F-measure: 0.6446321909076375\n",
            "Average NDCG: 0.9539926393565159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recommendations_df.to_csv('recommendations.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_fZeIi3dliOf",
        "outputId": "67d03c70-3d9e-4659-8bd5-05fd3c181c5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12f1ab69-4d9e-48a1-a434-d1e56a42c2c1\", \"recommendations.csv\", 130101)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}